{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@5ac61b3a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@5ac61b3a"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "val spark = SparkSession.builder.appName(\"Mortgage_ETL\").getOrCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object ReadPerformanceCsv\n",
       "defined object ReadAcquisitionCsv\n",
       "defined object NameMapping\n",
       "defined object CreatePerformanceDelinquency\n",
       "defined object CreateAcquisition\n",
       "defined object CleanAcquisitionPrime\n",
       "defined object MortgageXgBoost\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "object ReadPerformanceCsv {\n",
    "  def apply(spark: SparkSession, path: String): DataFrame = {\n",
    "    val performanceSchema = StructType(Array(\n",
    "      StructField(\"loan_id\", LongType),\n",
    "      StructField(\"monthly_reporting_period\", StringType),\n",
    "      StructField(\"servicer\", StringType),\n",
    "      StructField(\"interest_rate\", DoubleType),\n",
    "      StructField(\"current_actual_upb\", DoubleType),\n",
    "      StructField(\"loan_age\", DoubleType),\n",
    "      StructField(\"remaining_months_to_legal_maturity\", DoubleType),\n",
    "      StructField(\"adj_remaining_months_to_maturity\", DoubleType),\n",
    "      StructField(\"maturity_date\", StringType),\n",
    "      StructField(\"msa\", DoubleType),\n",
    "      StructField(\"current_loan_delinquency_status\", IntegerType),\n",
    "      StructField(\"mod_flag\", StringType),\n",
    "      StructField(\"zero_balance_code\", StringType),\n",
    "      StructField(\"zero_balance_effective_date\", StringType),\n",
    "      StructField(\"last_paid_installment_date\", StringType),\n",
    "      StructField(\"foreclosed_after\", StringType),\n",
    "      StructField(\"disposition_date\", StringType),\n",
    "      StructField(\"foreclosure_costs\", DoubleType),\n",
    "      StructField(\"prop_preservation_and_repair_costs\", DoubleType),\n",
    "      StructField(\"asset_recovery_costs\", DoubleType),\n",
    "      StructField(\"misc_holding_expenses\", DoubleType),\n",
    "      StructField(\"holding_taxes\", DoubleType),\n",
    "      StructField(\"net_sale_proceeds\", DoubleType),\n",
    "      StructField(\"credit_enhancement_proceeds\", DoubleType),\n",
    "      StructField(\"repurchase_make_whole_proceeds\", StringType),\n",
    "      StructField(\"other_foreclosure_proceeds\", DoubleType),\n",
    "      StructField(\"non_interest_bearing_upb\", DoubleType),\n",
    "      StructField(\"principal_forgiveness_upb\", StringType),\n",
    "      StructField(\"repurchase_make_whole_proceeds_flag\", StringType),\n",
    "      StructField(\"foreclosure_principal_write_off_amount\", StringType),\n",
    "      StructField(\"servicing_activity_indicator\", StringType))\n",
    "    )\n",
    "\n",
    "    val udf = spark.udf.register(\"get_quarter\", (path: String) => {\n",
    "      path.split(\"\\\\.\").head.split(\"_\").last\n",
    "    })\n",
    "\n",
    "    spark.read.format(\"csv\")\n",
    "      .option(\"nullValue\", \"\")\n",
    "      .option(\"header\", \"false\")\n",
    "      .option(\"delimiter\", \"|\")\n",
    "      .option(\"parserLib\", \"univocity\")\n",
    "      .schema(performanceSchema)\n",
    "      .load(path)\n",
    "      .withColumn(\"quarter\", udf(input_file_name()))\n",
    "  }\n",
    "}\n",
    "\n",
    "object ReadAcquisitionCsv {\n",
    "  def apply(spark: SparkSession, path: String): DataFrame = {\n",
    "    val acquisitionSchema = StructType(Array(\n",
    "      StructField(\"loan_id\", LongType),\n",
    "      StructField(\"orig_channel\", StringType),\n",
    "      StructField(\"seller_name\", StringType),\n",
    "      StructField(\"orig_interest_rate\", DoubleType),\n",
    "      StructField(\"orig_upb\", IntegerType),\n",
    "      StructField(\"orig_loan_term\", IntegerType),\n",
    "      StructField(\"orig_date\", StringType),\n",
    "      StructField(\"first_pay_date\", StringType),\n",
    "      StructField(\"orig_ltv\", DoubleType),\n",
    "      StructField(\"orig_cltv\", DoubleType),\n",
    "      StructField(\"num_borrowers\", DoubleType),\n",
    "      StructField(\"dti\", DoubleType),\n",
    "      StructField(\"borrower_credit_score\", DoubleType),\n",
    "      StructField(\"first_home_buyer\", StringType),\n",
    "      StructField(\"loan_purpose\", StringType),\n",
    "      StructField(\"property_type\", StringType),\n",
    "      StructField(\"num_units\", IntegerType),\n",
    "      StructField(\"occupancy_status\", StringType),\n",
    "      StructField(\"property_state\", StringType),\n",
    "      StructField(\"zip\", IntegerType),\n",
    "      StructField(\"mortgage_insurance_percent\", DoubleType),\n",
    "      StructField(\"product_type\", StringType),\n",
    "      StructField(\"coborrow_credit_score\", DoubleType),\n",
    "      StructField(\"mortgage_insurance_type\", DoubleType),\n",
    "      StructField(\"relocation_mortgage_indicator\", StringType))\n",
    "    )\n",
    "\n",
    "    val udf = spark.udf.register(\"get_quarter\", (path: String) => {\n",
    "      path.split(\"\\\\.\").head.split(\"_\").last\n",
    "    })\n",
    "\n",
    "    spark.read.format(\"csv\")\n",
    "      .option(\"header\", \"false\")\n",
    "      .option(\"delimiter\", \"|\")\n",
    "      .schema(acquisitionSchema)\n",
    "      .load(path)\n",
    "      .withColumn(\"quarter\", udf(input_file_name()))\n",
    "  }\n",
    "}\n",
    "\n",
    "object NameMapping {\n",
    "  def apply(): Map[String, String] = {\n",
    "    Map(\n",
    "      \"WITMER FUNDING, LLC\" -> \"Witmer\",\n",
    "      \"WELLS FARGO CREDIT RISK TRANSFER SECURITIES TRUST 2015\" -> \"Wells Fargo\",\n",
    "      \"WELLS FARGO BANK,  NA\" -> \"Wells Fargo\",\n",
    "      \"WELLS FARGO BANK, N.A.\" -> \"Wells Fargo\",\n",
    "      \"WELLS FARGO BANK, NA\" -> \"Wells Fargo\",\n",
    "      \"USAA FEDERAL SAVINGS BANK\" -> \"USAA\",\n",
    "      \"UNITED SHORE FINANCIAL SERVICES, LLC D\\\\/B\\\\/A UNITED WHOLESALE MORTGAGE\" -> \"United Seq(e\",\n",
    "      \"U.S. BANK N.A.\" -> \"US Bank\",\n",
    "      \"SUNTRUST MORTGAGE INC.\" -> \"Suntrust\",\n",
    "      \"STONEGATE MORTGAGE CORPORATION\" -> \"Stonegate Mortgage\",\n",
    "      \"STEARNS LENDING, LLC\" -> \"Stearns Lending\",\n",
    "      \"STEARNS LENDING, INC.\" -> \"Stearns Lending\",\n",
    "      \"SIERRA PACIFIC MORTGAGE COMPANY, INC.\" -> \"Sierra Pacific Mortgage\",\n",
    "      \"REGIONS BANK\" -> \"Regions\",\n",
    "      \"RBC MORTGAGE COMPANY\" -> \"RBC\",\n",
    "      \"QUICKEN LOANS INC.\" -> \"Quicken Loans\",\n",
    "      \"PULTE MORTGAGE, L.L.C.\" -> \"Pulte Mortgage\",\n",
    "      \"PROVIDENT FUNDING ASSOCIATES, L.P.\" -> \"Provident Funding\",\n",
    "      \"PROSPECT MORTGAGE, LLC\" -> \"Prospect Mortgage\",\n",
    "      \"PRINCIPAL RESIDENTIAL MORTGAGE CAPITAL RESOURCES, LLC\" -> \"Principal Residential\",\n",
    "      \"PNC BANK, N.A.\" -> \"PNC\",\n",
    "      \"PMT CREDIT RISK TRANSFER TRUST 2015-2\" -> \"PennyMac\",\n",
    "      \"PHH MORTGAGE CORPORATION\" -> \"PHH Mortgage\",\n",
    "      \"PENNYMAC CORP.\" -> \"PennyMac\",\n",
    "      \"PACIFIC UNION FINANCIAL, LLC\" -> \"Other\",\n",
    "      \"OTHER\" -> \"Other\",\n",
    "      \"NYCB MORTGAGE COMPANY, LLC\" -> \"NYCB\",\n",
    "      \"NEW YORK COMMUNITY BANK\" -> \"NYCB\",\n",
    "      \"NETBANK FUNDING SERVICES\" -> \"Netbank\",\n",
    "      \"NATIONSTAR MORTGAGE, LLC\" -> \"Nationstar Mortgage\",\n",
    "      \"METLIFE BANK, NA\" -> \"Metlife\",\n",
    "      \"LOANDEPOT.COM, LLC\" -> \"LoanDepot.com\",\n",
    "      \"J.P. MORGAN MADISON AVENUE SECURITIES TRUST, SERIES 2015-1\" -> \"JP Morgan Chase\",\n",
    "      \"J.P. MORGAN MADISON AVENUE SECURITIES TRUST, SERIES 2014-1\" -> \"JP Morgan Chase\",\n",
    "      \"JPMORGAN CHASE BANK, NATIONAL ASSOCIATION\" -> \"JP Morgan Chase\",\n",
    "      \"JPMORGAN CHASE BANK, NA\" -> \"JP Morgan Chase\",\n",
    "      \"JP MORGAN CHASE BANK, NA\" -> \"JP Morgan Chase\",\n",
    "      \"IRWIN MORTGAGE, CORPORATION\" -> \"Irwin Mortgage\",\n",
    "      \"IMPAC MORTGAGE CORP.\" -> \"Impac Mortgage\",\n",
    "      \"HSBC BANK USA, NATIONAL ASSOCIATION\" -> \"HSBC\",\n",
    "      \"HOMEWARD RESIDENTIAL, INC.\" -> \"Homeward Mortgage\",\n",
    "      \"HOMESTREET BANK\" -> \"Other\",\n",
    "      \"HOMEBRIDGE FINANCIAL SERVICES, INC.\" -> \"HomeBridge\",\n",
    "      \"HARWOOD STREET FUNDING I, LLC\" -> \"Harwood Mortgage\",\n",
    "      \"GUILD MORTGAGE COMPANY\" -> \"Guild Mortgage\",\n",
    "      \"GMAC MORTGAGE, LLC (USAA FEDERAL SAVINGS BANK)\" -> \"GMAC\",\n",
    "      \"GMAC MORTGAGE, LLC\" -> \"GMAC\",\n",
    "      \"GMAC (USAA)\" -> \"GMAC\",\n",
    "      \"FREMONT BANK\" -> \"Fremont Bank\",\n",
    "      \"FREEDOM MORTGAGE CORP.\" -> \"Freedom Mortgage\",\n",
    "      \"FRANKLIN AMERICAN MORTGAGE COMPANY\" -> \"Franklin America\",\n",
    "      \"FLEET NATIONAL BANK\" -> \"Fleet National\",\n",
    "      \"FLAGSTAR CAPITAL MARKETS CORPORATION\" -> \"Flagstar Bank\",\n",
    "      \"FLAGSTAR BANK, FSB\" -> \"Flagstar Bank\",\n",
    "      \"FIRST TENNESSEE BANK NATIONAL ASSOCIATION\" -> \"Other\",\n",
    "      \"FIFTH THIRD BANK\" -> \"Fifth Third Bank\",\n",
    "      \"FEDERAL HOME LOAN BANK OF CHICAGO\" -> \"Fedral Home of Chicago\",\n",
    "      \"FDIC, RECEIVER, INDYMAC FEDERAL BANK FSB\" -> \"FDIC\",\n",
    "      \"DOWNEY SAVINGS AND LOAN ASSOCIATION, F.A.\" -> \"Downey Mortgage\",\n",
    "      \"DITECH FINANCIAL LLC\" -> \"Ditech\",\n",
    "      \"CITIMORTGAGE, INC.\" -> \"Citi\",\n",
    "      \"CHICAGO MORTGAGE SOLUTIONS DBA INTERFIRST MORTGAGE COMPANY\" -> \"Chicago Mortgage\",\n",
    "      \"CHICAGO MORTGAGE SOLUTIONS DBA INTERBANK MORTGAGE COMPANY\" -> \"Chicago Mortgage\",\n",
    "      \"CHASE HOME FINANCE, LLC\" -> \"JP Morgan Chase\",\n",
    "      \"CHASE HOME FINANCE FRANKLIN AMERICAN MORTGAGE COMPANY\" -> \"JP Morgan Chase\",\n",
    "      \"CHASE HOME FINANCE (CIE 1)\" -> \"JP Morgan Chase\",\n",
    "      \"CHASE HOME FINANCE\" -> \"JP Morgan Chase\",\n",
    "      \"CASHCALL, INC.\" -> \"CashCall\",\n",
    "      \"CAPITAL ONE, NATIONAL ASSOCIATION\" -> \"Capital One\",\n",
    "      \"CALIBER HOME LOANS, INC.\" -> \"Caliber Funding\",\n",
    "      \"BISHOPS GATE RESIDENTIAL MORTGAGE TRUST\" -> \"Bishops Gate Mortgage\",\n",
    "      \"BANK OF AMERICA, N.A.\" -> \"Bank of America\",\n",
    "      \"AMTRUST BANK\" -> \"AmTrust\",\n",
    "      \"AMERISAVE MORTGAGE CORPORATION\" -> \"Amerisave\",\n",
    "      \"AMERIHOME MORTGAGE COMPANY, LLC\" -> \"AmeriHome Mortgage\",\n",
    "      \"ALLY BANK\" -> \"Ally Bank\",\n",
    "      \"ACADEMY MORTGAGE CORPORATION\" -> \"Academy Mortgage\",\n",
    "      \"NO CASH-OUT REFINANCE\" -> \"OTHER REFINANCE\",\n",
    "      \"REFINANCE - NOT SPECIFIED\" -> \"OTHER REFINANCE\",\n",
    "      \"Other REFINANCE\" -> \"OTHER REFINANCE\"\n",
    "    )\n",
    "  }\n",
    "}\n",
    "\n",
    "object CreatePerformanceDelinquency {\n",
    "  def prepare(df: DataFrame): DataFrame = {\n",
    "    df\n",
    "      .withColumn(\"monthly_reporting_period\", to_date(col(\"monthly_reporting_period\"), \"MM/dd/yyyy\"))\n",
    "      .withColumn(\"monthly_reporting_period_month\", month(col(\"monthly_reporting_period\")))\n",
    "      .withColumn(\"monthly_reporting_period_year\", year(col(\"monthly_reporting_period\")))\n",
    "      .withColumn(\"monthly_reporting_period_day\", dayofmonth(col(\"monthly_reporting_period\")))\n",
    "      .withColumn(\"last_paid_installment_date\", to_date(col(\"last_paid_installment_date\"), \"MM/dd/yyyy\"))\n",
    "      .withColumn(\"foreclosed_after\", to_date(col(\"foreclosed_after\"), \"MM/dd/yyyy\"))\n",
    "      .withColumn(\"disposition_date\", to_date(col(\"disposition_date\"), \"MM/dd/yyyy\"))\n",
    "      .withColumn(\"maturity_date\", to_date(col(\"maturity_date\"), \"MM/yyyy\"))\n",
    "      .withColumn(\"zero_balance_effective_date\", to_date(col(\"zero_balance_effective_date\"), \"MM/yyyy\"))\n",
    "      .withColumn(\"current_actual_upb\", col(\"current_actual_upb\"))\n",
    "      .withColumn(\"current_loan_delinquency_status\", col(\"current_loan_delinquency_status\"))\n",
    "  }\n",
    "\n",
    "  def apply(spark: SparkSession, df: DataFrame): DataFrame = {\n",
    "    import spark.implicits._\n",
    "\n",
    "    val aggDF = df\n",
    "      .select(\n",
    "        col(\"quarter\"),\n",
    "        col(\"loan_id\"),\n",
    "        col(\"current_loan_delinquency_status\"),\n",
    "        when(col(\"current_loan_delinquency_status\") >= 1, col(\"monthly_reporting_period\")).alias(\"delinquency_30\"),\n",
    "        when(col(\"current_loan_delinquency_status\") >= 3, col(\"monthly_reporting_period\")).alias(\"delinquency_90\"),\n",
    "        when(col(\"current_loan_delinquency_status\") >= 6, col(\"monthly_reporting_period\")).alias(\"delinquency_180\")\n",
    "      )\n",
    "      .groupBy(\"quarter\", \"loan_id\")\n",
    "      .agg(\n",
    "        max(\"current_loan_delinquency_status\").alias(\"delinquency_12\"),\n",
    "        min(\"delinquency_30\").alias(\"delinquency_30\"),\n",
    "        min(\"delinquency_90\").alias(\"delinquency_90\"),\n",
    "        min(\"delinquency_180\").alias(\"delinquency_180\")\n",
    "      )\n",
    "      .select(\n",
    "        col(\"quarter\"),\n",
    "        col(\"loan_id\"),\n",
    "        (col(\"delinquency_12\") >= 1).alias(\"ever_30\"),\n",
    "        (col(\"delinquency_12\") >= 3).alias(\"ever_90\"),\n",
    "        (col(\"delinquency_12\") >= 6).alias(\"ever_180\"),\n",
    "        col(\"delinquency_30\"),\n",
    "        col(\"delinquency_90\"),\n",
    "        col(\"delinquency_180\")\n",
    "      )\n",
    "\n",
    "    val joinedDf = df\n",
    "      .withColumnRenamed(\"monthly_reporting_period\", \"timestamp\")\n",
    "      .withColumnRenamed(\"monthly_reporting_period_month\", \"timestamp_month\")\n",
    "      .withColumnRenamed(\"monthly_reporting_period_year\", \"timestamp_year\")\n",
    "      .withColumnRenamed(\"current_loan_delinquency_status\", \"delinquency_12\")\n",
    "      .withColumnRenamed(\"current_actual_upb\", \"upb_12\")\n",
    "      .select(\"quarter\", \"loan_id\", \"timestamp\", \"delinquency_12\", \"upb_12\", \"timestamp_month\", \"timestamp_year\")\n",
    "      .join(aggDF, Seq(\"loan_id\", \"quarter\"), \"left_outer\")\n",
    "\n",
    "    // calculate the 12 month delinquency and upb values\n",
    "    val months = 12\n",
    "    val testDf = joinedDf\n",
    "      .crossJoin(0.until(months).toDF(\"month_y\"))\n",
    "      .select(\n",
    "        col(\"quarter\"),\n",
    "        floor(((col(\"timestamp_year\") * 12 + col(\"timestamp_month\")) - 24000) / months).alias(\"josh_mody\"),\n",
    "        floor(((col(\"timestamp_year\") * 12 + col(\"timestamp_month\")) - 24000 - col(\"month_y\")) / months).alias(\"josh_mody_n\"),\n",
    "        col(\"ever_30\"),\n",
    "        col(\"ever_90\"),\n",
    "        col(\"ever_180\"),\n",
    "        col(\"delinquency_30\"),\n",
    "        col(\"delinquency_90\"),\n",
    "        col(\"delinquency_180\"),\n",
    "        col(\"loan_id\"),\n",
    "        col(\"month_y\"),\n",
    "        col(\"delinquency_12\"),\n",
    "        col(\"upb_12\")\n",
    "      )\n",
    "      .groupBy(\"quarter\", \"loan_id\", \"josh_mody_n\", \"ever_30\", \"ever_90\", \"ever_180\", \"delinquency_30\", \"delinquency_90\", \"delinquency_180\", \"month_y\")\n",
    "      .agg(max(\"delinquency_12\").alias(\"delinquency_12\"), min(\"upb_12\").alias(\"upb_12\"))\n",
    "      .withColumn(\"timestamp_year\", floor((lit(24000) + (col(\"josh_mody_n\") * lit(months)) + (col(\"month_y\") - 1)) / lit(12)))\n",
    "      .withColumn(\"timestamp_month_tmp\", pmod((lit(24000) + (col(\"josh_mody_n\") * lit(months)) + col(\"month_y\")), lit(12)))\n",
    "      .withColumn(\"timestamp_month\", when(col(\"timestamp_month_tmp\") === lit(0), lit(12)).otherwise(col(\"timestamp_month_tmp\")))\n",
    "      .withColumn(\"delinquency_12\", ((col(\"delinquency_12\") > 3).cast(\"int\") + (col(\"upb_12\") === 0).cast(\"int\")).alias(\"delinquency_12\"))\n",
    "      .drop(\"timestamp_month_tmp\", \"josh_mody_n\", \"month_y\")\n",
    "\n",
    "    df.withColumnRenamed(\"monthly_reporting_period_month\", \"timestamp_month\")\n",
    "      .withColumnRenamed(\"monthly_reporting_period_year\", \"timestamp_year\")\n",
    "      .join(testDf, Seq(\"quarter\", \"loan_id\", \"timestamp_year\", \"timestamp_month\"), \"left\").drop(\"timestamp_year\", \"timestamp_month\")\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "object CreateAcquisition {\n",
    "  def apply(spark: SparkSession, df: DataFrame): DataFrame = {\n",
    "    val names = NameMapping()\n",
    "    val nameMapping = udf((name: String) => names.getOrElse(name, null))\n",
    "    df\n",
    "      .withColumn(\"old_name\", col(\"seller_name\"))\n",
    "      .withColumn(\"seller_name\", nameMapping(col(\"seller_name\")))\n",
    "      .withColumn(\"orig_date\", to_date(col(\"orig_date\"), \"MM/yyyy\"))\n",
    "      .withColumn(\"first_pay_date\", to_date(col(\"first_pay_date\"), \"MM/yyyy\"))\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "object CleanAcquisitionPrime {\n",
    "  def apply(spark: SparkSession, perfDF: DataFrame, acqDF: DataFrame): DataFrame = {\n",
    "    val perf = CreatePerformanceDelinquency(spark, perfDF)\n",
    "    val acq = CreateAcquisition(spark, acqDF)\n",
    "\n",
    "    perf.join(acq, Seq(\"loan_id\", \"quarter\"), \"left_outer\").drop(\"quarter\")\n",
    "  }\n",
    "}\n",
    "\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{FeatureHasher, StringIndexer, VectorAssembler}\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.DoubleType\n",
    "\n",
    "object MortgageXgBoost {\n",
    "  val catCols = List(\n",
    "    \"orig_channel\",\n",
    "    \"first_home_buyer\",\n",
    "    \"loan_purpose\",\n",
    "    \"property_type\",\n",
    "    \"occupancy_status\",\n",
    "    \"property_state\",\n",
    "    \"product_type\",\n",
    "    \"relocation_mortgage_indicator\",\n",
    "    \"seller_name\",\n",
    "    \"mod_flag\"\n",
    "  )\n",
    "\n",
    "  val numericCols = List(\n",
    "    \"orig_interest_rate\",\n",
    "    \"orig_upb\",\n",
    "    \"orig_loan_term\",\n",
    "    \"orig_ltv\",\n",
    "    \"orig_cltv\",\n",
    "    \"num_borrowers\",\n",
    "    \"dti\",\n",
    "    \"borrower_credit_score\",\n",
    "    \"num_units\",\n",
    "    \"zip\",\n",
    "    \"mortgage_insurance_percent\",\n",
    "    \"current_loan_delinquency_status\",\n",
    "    \"current_actual_upb\",\n",
    "    \"interest_rate\",\n",
    "    \"loan_age\",\n",
    "    \"msa\",\n",
    "    \"non_interest_bearing_upb\",\n",
    "    \"delinquency_12\"\n",
    "  )\n",
    "\n",
    "  val allCols: List[String] = catCols ++ numericCols\n",
    "\n",
    "  def transform(df: DataFrame): (DataFrame, DataFrame) = {\n",
    "    val featureDF = df.select(catCols.map(c => (md5(col(c)) % 100).alias(c)) ++ numericCols.map(c => col(c)): _*)\n",
    "      .withColumn(\"delinquency_12\", when(col(\"delinquency_12\") > 0, 1).otherwise(0))\n",
    "      .na.fill(0.0f)\n",
    "    val Array(dtrain, dtest) = featureDF.randomSplit(Array(0.8, 0.2))\n",
    "    (dtrain, dtest)\n",
    "  }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datasets/test/raw/mortgage/perf/Performance_2000Q1.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2000Q1.txt*\n",
      "9094679\n",
      "/datasets/test/raw/mortgage/perf/Performance_2000Q2.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2000Q2.txt*\n",
      "8208081\n",
      "/datasets/test/raw/mortgage/perf/Performance_2000Q3.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2000Q3.txt*\n",
      "8726405\n",
      "/datasets/test/raw/mortgage/perf/Performance_2000Q4.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2000Q4.txt*\n",
      "10161217\n",
      "/datasets/test/raw/mortgage/perf/Performance_2001Q1.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2001Q1.txt*\n",
      "15539871\n",
      "/datasets/test/raw/mortgage/perf/Performance_2001Q2.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2001Q2.txt*\n",
      "31540064\n",
      "/datasets/test/raw/mortgage/perf/Performance_2001Q3.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2001Q3.txt*\n",
      "27947419\n",
      "/datasets/test/raw/mortgage/perf/Performance_2001Q4.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2001Q4.txt*\n",
      "37266966\n",
      "/datasets/test/raw/mortgage/perf/Performance_2002Q1.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2002Q1.txt*\n",
      "41680323\n",
      "/datasets/test/raw/mortgage/perf/Performance_2002Q2.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2002Q2.txt*\n",
      "26283319\n",
      "/datasets/test/raw/mortgage/perf/Performance_2002Q3.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2002Q3.txt*\n",
      "32608048\n",
      "/datasets/test/raw/mortgage/perf/Performance_2002Q4.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2002Q4.txt*\n",
      "70901530\n",
      "/datasets/test/raw/mortgage/perf/Performance_2003Q1.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2003Q1.txt*\n",
      "92189906\n",
      "/datasets/test/raw/mortgage/perf/Performance_2003Q2.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2003Q2.txt*\n",
      "122601746\n",
      "/datasets/test/raw/mortgage/perf/Performance_2003Q3.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2003Q3.txt*\n",
      "143905635\n",
      "/datasets/test/raw/mortgage/perf/Performance_2003Q4.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2003Q4.txt*\n",
      "64629213\n",
      "/datasets/test/raw/mortgage/perf/Performance_2004Q1.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2004Q1.txt*\n",
      "33966494\n",
      "/datasets/test/raw/mortgage/perf/Performance_2004Q2.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2004Q2.txt*\n",
      "48370771\n",
      "/datasets/test/raw/mortgage/perf/Performance_2004Q3.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2004Q3.txt*\n",
      "26983014\n",
      "/datasets/test/raw/mortgage/perf/Performance_2004Q4.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2004Q4.txt*\n",
      "26805681\n",
      "/datasets/test/raw/mortgage/perf/Performance_2005Q1.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2005Q1.txt*\n",
      "22985763\n",
      "/datasets/test/raw/mortgage/perf/Performance_2005Q2.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2005Q2.txt*\n",
      "25187521\n",
      "/datasets/test/raw/mortgage/perf/Performance_2005Q3.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2005Q3.txt*\n",
      "33132450\n",
      "/datasets/test/raw/mortgage/perf/Performance_2005Q4.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2005Q4.txt*\n",
      "27452476\n",
      "/datasets/test/raw/mortgage/perf/Performance_2006Q1.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2006Q1.txt*\n",
      "16869088\n",
      "/datasets/test/raw/mortgage/perf/Performance_2006Q2.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2006Q2.txt*\n",
      "18307297\n",
      "/datasets/test/raw/mortgage/perf/Performance_2006Q3.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2006Q3.txt*\n",
      "15325099\n",
      "/datasets/test/raw/mortgage/perf/Performance_2006Q4.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2006Q4.txt*\n",
      "16569478\n",
      "/datasets/test/raw/mortgage/perf/Performance_2007Q1.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2007Q1.txt*\n",
      "15328325\n",
      "/datasets/test/raw/mortgage/perf/Performance_2007Q2.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2007Q2.txt*\n",
      "16974092\n",
      "/datasets/test/raw/mortgage/perf/Performance_2007Q3.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2007Q3.txt*\n",
      "16661889\n",
      "/datasets/test/raw/mortgage/perf/Performance_2007Q4.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2007Q4.txt*\n",
      "20488552\n",
      "/datasets/test/raw/mortgage/perf/Performance_2008Q1.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2008Q1.txt*\n",
      "20282080\n",
      "/datasets/test/raw/mortgage/perf/Performance_2008Q2.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2008Q2.txt*\n",
      "22861250\n",
      "/datasets/test/raw/mortgage/perf/Performance_2008Q3.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2008Q3.txt*\n",
      "15331070\n",
      "/datasets/test/raw/mortgage/perf/Performance_2008Q4.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2008Q4.txt*\n",
      "13398675\n",
      "/datasets/test/raw/mortgage/perf/Performance_2009Q1.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2009Q1.txt*\n",
      "30738483\n",
      "/datasets/test/raw/mortgage/perf/Performance_2009Q2.txt*\n",
      "/datasets/test/raw/mortgage/acq/Acquisition_2009Q2.txt*\n",
      "41131991\n"
     ]
    }
   ],
   "source": [
    "val dataRoot=\"/datasets/test/raw/mortgage\"\n",
    "val perfPath=dataRoot+\"/perf/Performance_2000Q1.txt\"\n",
    "val acqPath=dataRoot+\"/acq/Acquisition_2000Q1.txt\"\n",
    "val featureRoot=\"/datasets/test/mortgage\"\n",
    "\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "\n",
    "val storageLevel = StorageLevel.MEMORY_ONLY\n",
    "\n",
    "var year = 0\n",
    "var quater = 0\n",
    "for ( year <- 2000 to 2016 ) {\n",
    "    for ( quater <- 1 to 4) {\n",
    "        val perfPath = dataRoot + \"/perf/Performance_\" + year.toString + \"Q\" + quater.toString + \".txt*\"\n",
    "        val acqPath = dataRoot + \"/acq/Acquisition_\" + year.toString + \"Q\" + quater.toString + \".txt*\"\n",
    "        println(perfPath)\n",
    "        println(acqPath)\n",
    "        \n",
    "        val perfCsv = ReadPerformanceCsv(spark, perfPath).persist(storageLevel)\n",
    "        println(perfCsv.count())\n",
    "        val acqCsv = ReadAcquisitionCsv(spark, acqPath).persist(storageLevel)\n",
    "        val perf = CreatePerformanceDelinquency.prepare(perfCsv)\n",
    "        val cleanDF = CleanAcquisitionPrime(spark, perf, acqCsv).persist(storageLevel)\n",
    "        val (dfTrain, dfEval) = MortgageXgBoost.transform(cleanDF)\n",
    "        dfTrain.persist(storageLevel)\n",
    "        dfEval.persist(storageLevel)\n",
    "        val parquetDir=featureRoot + \"/parquet/\" + year.toString + \"Q\" + quater.toString\n",
    "        dfTrain.write.mode(\"overwrite\").parquet(parquetDir + \"/train\")\n",
    "        dfEval.write.mode(\"overwrite\").parquet(parquetDir + \"/eval\")\n",
    "        \n",
    "        \n",
    "        val csvDir=featureRoot + \"/csv/\" + year.toString + \"Q\" + quater.toString\n",
    "        dfTrain.write.mode(\"overwrite\").option(\"header\", \"true\").csv(csvDir + \"/train\")\n",
    "        dfEval.write.mode(\"overwrite\").option(\"header\", \"true\").csv(csvDir + \"/eval\")\n",
    "        \n",
    "        perfCsv.unpersist()\n",
    "        acqCsv.unpersist()\n",
    "        cleanDF.unpersist()\n",
    "        dfTrain.unpersist()\n",
    "        dfEval.unpersist()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark243 - Scala",
   "language": "scala",
   "name": "spark243_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
